{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJtwEuNem_qK",
        "outputId": "e4ea2d38-6899-4c08-daab-01a2feae3870"
      },
      "outputs": [],
      "source": [
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78RiHD9zpY72",
        "outputId": "9d39ef63-0abb-468b-af3f-f6827a563481"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/content/drive\")\n",
        "    import zipfile\n",
        "\n",
        "    with zipfile.ZipFile(\"/content/drive/MyDrive/ML/train.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"./\")\n",
        "    with zipfile.ZipFile(\"/content/drive/MyDrive/ML/test.zip\", \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"./\")\n",
        "    trainDataFolderPath = \"/content/train/\"\n",
        "    testDataFolderPath = \"/content/test/\"\n",
        "except:\n",
        "    trainDataFolderPath = \"Data/train/\"\n",
        "    testDataFolderPath = \"Data/test/\"\n",
        "    print(\"Using Local Machine\")\n",
        "\n",
        "# try:\n",
        "#     from google.colab import drive\n",
        "\n",
        "#     drive.mount(\"/content/drive\")\n",
        "#     import zipfile\n",
        "\n",
        "#     with zipfile.ZipFile(\n",
        "#         \"/content/drive/MyDrive/ML/Transformed Train.zip\", \"r\"\n",
        "#     ) as zip_ref:\n",
        "#         zip_ref.extractall(\"./\")\n",
        "#     with zipfile.ZipFile(\n",
        "#         \"/content/drive/MyDrive/ML/Transformed Test.zip\", \"r\"\n",
        "#     ) as zip_ref:\n",
        "#         zip_ref.extractall(\"./\")\n",
        "#     trainDataFolderPath = \"/content/Transformed Train/\"\n",
        "#     testDataFolderPath = \"/content/Transformed Test/\"\n",
        "# except:\n",
        "#     trainDataFolderPath = \"Data/Transformed Train/\"\n",
        "    # testDataFolderPath = \"Data/Transformed Test/\"\n",
        "    # print(\"Using Local Machine\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-uGQgvZpY74"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "import copy\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from itertools import product\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rxOcexPpY75"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "from keras.layers import (\n",
        "    Conv2D,\n",
        "    BatchNormalization,\n",
        "    MaxPooling2D,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    Activation,\n",
        "    Dense,\n",
        ")\n",
        "from keras.callbacks import (\n",
        "    EarlyStopping,\n",
        "    ModelCheckpoint,\n",
        "    ReduceLROnPlateau,\n",
        "    TensorBoard,\n",
        ")\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyrRl_DRpY75",
        "outputId": "66542b44-c213-4d91-fb48-f195fc5be060"
      },
      "outputs": [],
      "source": [
        "physicalDevices = tf.config.list_physical_devices(\"GPU\")\n",
        "print(physicalDevices)\n",
        "if len(physicalDevices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physicalDevices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqJDoMBSpY75"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "modelPath = 'SavedModels/model1.sav'\n",
        "logsDir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboardCBK = TensorBoard(log_dir=logsDir, histogram_freq=1)\n",
        "earlyStoppingCBK = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=200)\n",
        "modelCBK = ModelCheckpoint(\n",
        "    modelPath+'.mcp.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "reduceLRPlateauCBK  = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                            patience=200,\n",
        "                                            verbose=1,\n",
        "                                            factor=0.2)\n",
        "\n",
        "callbacks = [earlyStoppingCBK,\n",
        "             reduceLRPlateauCBK, tensorboardCBK]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjZLYc_HpY76"
      },
      "outputs": [],
      "source": [
        "def ShowImage(imageName: str, image: np.ndarray):\n",
        "    plt.imshow(image)\n",
        "    plt.title(imageName)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0IAg-8XpY76"
      },
      "outputs": [],
      "source": [
        "def DrawBoundaryBoxs(\n",
        "    frame: np.ndarray,\n",
        "    boundryBox: list,\n",
        "    color: tuple = (0, 255, 0),\n",
        "    thickness: int = 2,\n",
        "):\n",
        "    [x, y, w, h] = boundryBox\n",
        "    frame = cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness)\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QA21MLtNm_qO"
      },
      "outputs": [],
      "source": [
        "def DisplayPrediction(frame: np.ndarray, Name: str = None):\n",
        "    if(not Name):\n",
        "        Name =  \"No Face Detected\"\n",
        "    frame_width = frame.shape[:2]\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 1\n",
        "    font_color = (0, 255, 0)  # Green color\n",
        "    line_type = 2\n",
        "    text_size = cv2.getTextSize(Name, font, font_scale, line_type)[0]\n",
        "    text_x = (frame_width - text_size[0]) // 2  # Centered horizontally\n",
        "    text_y = 30\n",
        "    frame = cv2.putText(frame, Name, (text_x, text_y), font, font_scale, font_color, line_type)\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jyc5gYapY76"
      },
      "outputs": [],
      "source": [
        "def DetectFaces(frame: np.ndarray, faceCascade: MTCNN):\n",
        "    # grayScaleImage = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    detectedFacesBBoxs = faceCascade.detect_faces(frame)\n",
        "\n",
        "    detectedFacesBBoxs = [detectedFacesBBox['box'] for detectedFacesBBox in detectedFacesBBoxs]\n",
        "    return detectedFacesBBoxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ttBHen7pY76"
      },
      "outputs": [],
      "source": [
        "def CropImage(image: np.ndarray, bBox: list):\n",
        "    [x, y, w, h] = bBox\n",
        "    croppedImage = image[y : y + h, x : x + w]\n",
        "    return croppedImage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCE1t7-FpY76"
      },
      "outputs": [],
      "source": [
        "def ResizeImage(image: np.ndarray, resize: tuple = (100, 100)):\n",
        "    image = cv2.resize(image, resize)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6aYxIvUpY77"
      },
      "outputs": [],
      "source": [
        "def LoadDataSet(folderPath: str):\n",
        "    if not (os.path.exists(folderPath)):\n",
        "        print(\"Please ensure that FolderPath is valid\")\n",
        "        return None\n",
        "    labelNames = os.listdir(folderPath)\n",
        "    imageDataset = []\n",
        "    labelDataset = []\n",
        "    for folderName in labelNames:\n",
        "        if not folderName == \".DS_Store\":\n",
        "            imageList = os.listdir(folderPath + folderName)\n",
        "            for imageName in tqdm(imageList):\n",
        "                if not imageName == \".DS_Store\":\n",
        "                    imageDataset.append(\n",
        "                        # ResizeImage(\n",
        "                            cv2.imread(folderPath + folderName + \"/\" + imageName)\n",
        "                        # )\n",
        "                    )\n",
        "                    labelDataset.append(folderName)\n",
        "\n",
        "    return imageDataset, labelDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zl6BECCpY77"
      },
      "outputs": [],
      "source": [
        "def GetMaxAreabBox(bBoxes: list, imageArea: int):\n",
        "    bestbBox = []\n",
        "    maxArea = 0\n",
        "    for bBox in bBoxes:\n",
        "        [x, y, w, h] = bBox\n",
        "        if w * h > maxArea:\n",
        "            maxArea = w * h\n",
        "            bestbBox = bBox\n",
        "    return bestbBox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZgwD0IfpY77"
      },
      "outputs": [],
      "source": [
        "def TransformFaces(imageDataset: list, labelDataset: list, min_face_size: int = 20):\n",
        "    faceCascade = MTCNN(min_face_size=min_face_size)\n",
        "    faceImages = []\n",
        "    labels = []\n",
        "    zipped = zip(imageDataset, labelDataset)\n",
        "    for image, label in tqdm(zipped):\n",
        "        bBoxes = DetectFaces(image, faceCascade)\n",
        "        imageArea = image.shape[0] * image.shape[1]\n",
        "\n",
        "        if len(bBoxes):\n",
        "            bBox = GetMaxAreabBox(bBoxes, imageArea)\n",
        "            if len(bBox):\n",
        "                faceImage = CropImage(image, bBox)\n",
        "                faceImages.append(faceImage)\n",
        "                labels.append(label)\n",
        "    return faceImages, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWbh-zW8pY77"
      },
      "outputs": [],
      "source": [
        "# trainingImageDataset, trainingLabelDataset = LoadDataSet(trainDataFolderPath)\n",
        "# combined = list(zip(trainingImageDataset, trainingLabelDataset))\n",
        "# np.random.shuffle(combined)\n",
        "# trainingImageDataset, trainingLabelDataset = zip(*combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "kntxVipLm_qP",
        "outputId": "dd1a1e0e-4ed1-487a-b97d-0d5914bbd1b1"
      },
      "outputs": [],
      "source": [
        "trainingImageDataset, trainingLabelDataset = LoadDataSet(trainDataFolderPath)\n",
        "ShowImage(trainingLabelDataset[0],trainingImageDataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMrbwA9gm_qP",
        "outputId": "0b7975c8-c12f-4ae0-9700-82415d4002b9"
      },
      "outputs": [],
      "source": [
        "trainingImageDataset, trainingLabelDataset = TransformFaces(\n",
        "    trainingImageDataset, trainingLabelDataset\n",
        ")\n",
        "# ShowImage(trainingLabelDataset[0],trainingImageDataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Xe6RK_y9m_qP",
        "outputId": "02716d87-5997-45af-e5a6-d2cd79538f9b"
      },
      "outputs": [],
      "source": [
        "\n",
        "ShowImage(trainingLabelDataset[0],trainingImageDataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r24tTozCm_qP",
        "outputId": "38feed84-6b44-4803-edc0-632a336843af"
      },
      "outputs": [],
      "source": [
        "trainingImageDataset = [ResizeImage(image) for image in tqdm(trainingImageDataset)]\n",
        "encoder = LabelEncoder()\n",
        "encoder = encoder.fit(trainingLabelDataset)\n",
        "trainingLabelDataset = encoder.transform(trainingLabelDataset)\n",
        "trainingLabelDataset = to_categorical(trainingLabelDataset, num_classes=4)\n",
        "trainingImageDataset = np.array(trainingImageDataset)\n",
        "trainingLabelDataset = np.array(trainingLabelDataset)\n",
        "numClasses = len(encoder.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCRojxQmm_qP",
        "outputId": "51ff193d-97ba-418c-8f7f-3a16682196e8"
      },
      "outputs": [],
      "source": [
        "print(numClasses)\n",
        "print(trainingImageDataset.shape)\n",
        "print(trainingLabelDataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ELoHkypY77",
        "outputId": "1223f4f4-08a4-4e41-fb3f-cf4e685be96a"
      },
      "outputs": [],
      "source": [
        "testImageDataset, testLabelDataset = LoadDataSet(testDataFolderPath)\n",
        "testImageDataset, testLabelDataset = TransformFaces(testImageDataset, testLabelDataset)\n",
        "testImageDataset = [ResizeImage(image) for image in tqdm(testImageDataset)]\n",
        "testLabelDataset = encoder.transform(testLabelDataset)\n",
        "testLabelDataset = to_categorical(testLabelDataset, num_classes=numClasses)\n",
        "testImageDataset = np.array(testImageDataset)\n",
        "testLabelDataset = np.array(testLabelDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TvcAzcV05Te",
        "outputId": "b4c3a112-cfb4-4d1d-d9a8-cd9e682ae9f4"
      },
      "outputs": [],
      "source": [
        "print(testImageDataset.shape)\n",
        "print(testLabelDataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMqO93bLpY78"
      },
      "outputs": [],
      "source": [
        "def CreateModel(inputShape: tuple = (100, 100, 3), numClasses: int = 4):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=inputShape))\n",
        "    model.add(BatchNormalization())  # ----------------\n",
        "    model.add(Conv2D(64, kernel_size=3, activation=\"relu\"))\n",
        "    model.add(BatchNormalization())  # ----------------\n",
        "    model.add(Conv2D(64, kernel_size=5, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(BatchNormalization())  # ----------------\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))  # ----------------\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, kernel_size=5, padding=\"same\", activation=\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Dense(numClasses, activation=\"softmax\"))\n",
        "    learning_rate = 0.001\n",
        "    optimizer = RMSprop(lr=learning_rate)\n",
        "    # optimizer=\"adam\"\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        optimizer=optimizer,\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP7Y1tphpY78"
      },
      "outputs": [],
      "source": [
        "epochs = 100\n",
        "batch_size = 256\n",
        "validation_steps = 50\n",
        "steps_per_epoch = trainingImageDataset.shape[0] // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiNf7jq5pY78",
        "outputId": "f9c17cda-87a2-4e70-9044-1642786a8060"
      },
      "outputs": [],
      "source": [
        "model = CreateModel(numClasses= numClasses)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNuXTbtMy0aP",
        "outputId": "f9288dd5-fe3b-484e-9db4-7c810f417524"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    trainingImageDataset,\n",
        "    trainingLabelDataset,\n",
        "    batch_size=32,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.1,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFcL4dZZm_qT"
      },
      "outputs": [],
      "source": [
        "# datagen = ImageDataGenerator(\n",
        "#     rescale=1.0 / 255.0,\n",
        "#     rotation_range=10,\n",
        "#     width_shift_range=0.25,\n",
        "#     height_shift_range=0.25,\n",
        "#     shear_range=0.1,\n",
        "#     zoom_range=0.25,\n",
        "#     horizontal_flip=False,\n",
        "# )\n",
        "# trainingDataset = datagen.flow(trainingImageDataset, trainingLabelDataset)\n",
        "# testDataset = datagen.flow(testImageDataset, testLabelDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVlaxymnpY78"
      },
      "outputs": [],
      "source": [
        "# history = model.fit_generator(\n",
        "#     trainingDataset,\n",
        "#     steps_per_epoch=steps_per_epoch,\n",
        "#     epochs=epochs,\n",
        "#     validation_data=testDataset,\n",
        "#     validation_steps=validation_steps,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=1,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bq6G3j07wAv",
        "outputId": "13416e27-9748-4317-b4db-232a15e83565"
      },
      "outputs": [],
      "source": [
        "print(testImageDataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UyJgYmv8K9d",
        "outputId": "99db8e4b-a7d4-424f-9d65-11df235d9f7f"
      },
      "outputs": [],
      "source": [
        "testImageDataset, testLabelDataset = LoadDataSet(testDataFolderPath)\n",
        "testImageDataset, testLabelDataset = TransformFaces(testImageDataset, testLabelDataset)\n",
        "testImageDataset = [ResizeImage(image) for image in tqdm(testImageDataset)]\n",
        "testLabelDataset = encoder.transform(testLabelDataset)\n",
        "testLabelDataset = to_categorical(testLabelDataset, num_classes=numClasses)\n",
        "testImageDataset = np.array(testImageDataset)\n",
        "testLabelDataset = np.array(testLabelDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP0aLdsHm_qT",
        "outputId": "4f731c8c-dd6b-4adc-8a22-8e1c79d74944"
      },
      "outputs": [],
      "source": [
        "accuracy = model.evaluate(testImageDataset, testLabelDataset)\n",
        "print(\"accuracy:\", accuracy[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xn8PQIKy7ghV",
        "outputId": "eabb00c9-96cc-4714-b0fa-16d044a7a1ff"
      },
      "outputs": [],
      "source": [
        "for images in testImageDataset:\n",
        "    prediction = model.predict(images.reshape(1, 100, 100, 3))\n",
        "    print(np.argmax(prediction))\n",
        "    prediction = encoder.inverse_transform([np.argmax(prediction)])\n",
        "    ShowImage(prediction[0], images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-RWJKjom_qT",
        "outputId": "ca218fcb-c2bc-487c-868c-b72cf5a42d41"
      },
      "outputs": [],
      "source": [
        "model.save('MyModel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jX6tfCfm_qT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
